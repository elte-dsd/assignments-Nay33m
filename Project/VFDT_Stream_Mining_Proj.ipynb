{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VFDT_Stream_Mining_Proj.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbU0s5hq5AWk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Import neccessary inbuilt functions\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "import time\n",
        "from itertools import combinations\n",
        "\n",
        "# Code to read csv file into Colaboratory:\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Em4LjaXI5pg5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "link = 'https://drive.google.com/open?id=1rA4YcPrXc43YnlSRbnvxcSzz9ZNbJMWx' # The shareable link\n",
        "fluff, id = link.split('=')\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('bank.csv')  \n",
        "\n",
        "# from google.colab import files\n",
        "# uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fF-0kyg6Bbd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "67f3d923-cdef-4713-92d9-daeb4d074130"
      },
      "source": [
        "#Explore Dataset\n",
        "df = pd.read_csv('bank.csv', header=0, sep=';')\n",
        "#4521 rows and 17 columns\n",
        "df.shape"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4521, 17)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ph_0d2vh6YSc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e44420c3-14a8-4bc1-c435-faa25d632f4f"
      },
      "source": [
        "rows=4521\n",
        "title = list(df.columns.values)\n",
        "features = title[:-1]\n",
        "#Dependent variable to predict Independent value Y\n",
        "print(features)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['age', 'job', 'marital', 'education', 'default', 'balance', 'housing', 'loan', 'contact', 'day', 'month', 'duration', 'campaign', 'pdays', 'previous', 'poutcome']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QBBxWAg7BMp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "d49d7974-64ca-4a9c-941e-f35ba4118bb1"
      },
      "source": [
        "#change month string to int\n",
        "import calendar\n",
        "d = dict((v.lower(),k) for k,v in enumerate(calendar.month_abbr))\n",
        "df.month = df.month.map(d)\n",
        "print(df.head(10))\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   age            job  marital  education  ... pdays  previous poutcome   y\n",
            "0   30     unemployed  married    primary  ...    -1         0  unknown  no\n",
            "1   33       services  married  secondary  ...   339         4  failure  no\n",
            "2   35     management   single   tertiary  ...   330         1  failure  no\n",
            "3   30     management  married   tertiary  ...    -1         0  unknown  no\n",
            "4   59    blue-collar  married  secondary  ...    -1         0  unknown  no\n",
            "5   35     management   single   tertiary  ...   176         3  failure  no\n",
            "6   36  self-employed  married   tertiary  ...   330         2    other  no\n",
            "7   39     technician  married  secondary  ...    -1         0  unknown  no\n",
            "8   41   entrepreneur  married   tertiary  ...    -1         0  unknown  no\n",
            "9   43       services  married    primary  ...   147         2  failure  no\n",
            "\n",
            "[10 rows x 17 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zaKxlYrw7R2p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cf057c51-63a9-497e-a8be-18d0f64b70b4"
      },
      "source": [
        "# unique values for each feature to use in VFDT\n",
        "feature_values = {f:None for f in features}\n",
        "for f in features:\n",
        "    feature_values[f] = df[f].unique()\n",
        "\n",
        "print(feature_values)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'age': array([30, 33, 35, 59, 36, 39, 41, 43, 20, 31, 40, 56, 37, 25, 38, 42, 44,\n",
            "       26, 55, 67, 53, 68, 32, 49, 78, 23, 52, 34, 61, 45, 48, 57, 54, 63,\n",
            "       51, 29, 50, 27, 60, 28, 21, 58, 22, 46, 24, 77, 75, 47, 70, 65, 64,\n",
            "       62, 66, 19, 81, 83, 80, 71, 72, 69, 79, 73, 86, 74, 76, 87, 84]), 'job': array(['unemployed', 'services', 'management', 'blue-collar',\n",
            "       'self-employed', 'technician', 'entrepreneur', 'admin.', 'student',\n",
            "       'housemaid', 'retired', 'unknown'], dtype=object), 'marital': array(['married', 'single', 'divorced'], dtype=object), 'education': array(['primary', 'secondary', 'tertiary', 'unknown'], dtype=object), 'default': array(['no', 'yes'], dtype=object), 'balance': array([ 1787,  4789,  1350, ...,  -333, -3313,  1137]), 'housing': array(['no', 'yes'], dtype=object), 'loan': array(['no', 'yes'], dtype=object), 'contact': array(['cellular', 'unknown', 'telephone'], dtype=object), 'day': array([19, 11, 16,  3,  5, 23, 14,  6, 17, 20, 13, 30, 29, 27,  7, 18, 12,\n",
            "       21, 26, 22,  2,  4, 15,  8, 28,  9,  1, 10, 31, 25, 24]), 'month': array([10,  5,  4,  6,  2,  8,  1,  7, 11,  9,  3, 12]), 'duration': array([  79,  220,  185,  199,  226,  141,  341,  151,   57,  313,  273,\n",
            "        113,  328,  261,   89,  189,  239,  114,  250,  148,   96,  140,\n",
            "        109,  125,  169,  182,  247,  119,  149,   74,  897,   81,   40,\n",
            "        958,  354,  150,   97,  132,  765,   16,  609,  106,  365,  205,\n",
            "         11,  105,   59,  425,  204,  181, 1018, 1740,   98,  441,  272,\n",
            "        159,  295,  314,  579,  554,  323,  227,  134,  223,  155,  130,\n",
            "        630,  164,  268,  380,  154,  221,   67,  367,   87,  701,  652,\n",
            "         63,  398,  224,  406,   60,  521,  279,  203,  201,  372,  391,\n",
            "        165,  231,  291,  233,  473,  736,  337,  553,  345,   65,    9,\n",
            "        259,  371,  280,  243,  435,  258,    7,  317,   76,  170,  386,\n",
            "         83,   69,  564,  588,  779,  281, 1877,   51,   32,  176,  161,\n",
            "        187,   24,   85,  236,   54,   71,  489,   39,  455,   86,  190,\n",
            "         45,  168,  194,  103,  333,  102,   92,  213,  289,   77,  324,\n",
            "         84,   10,   35,   82,  676,   80,  549,  135,  412,  101,  253,\n",
            "        166,   18,  147,   14,   61,  377,  152,  382,  543,  240,   48,\n",
            "        471,  285,  301,  768, 1337,  403,  139,  196,  115,   17,   95,\n",
            "        198,  654,  256,  834,   20,  178,  111,  186,  297,  210,  112,\n",
            "        222,  195,  123,  145,  124,  216,  483,  690,  344,  673,  144,\n",
            "        246,  361,  375, 1097,  180,  373,  230,   58,   88,  487,   29,\n",
            "        484,  262,  644,  699,   49,   64,  121,  197,  331,  138,  312,\n",
            "        120,  526,  211,   62,  988,  451, 1030, 1484,  445,  383,  605,\n",
            "        330,  171,  442,  772,  249,  357,  271,  783,  472,  395,   56,\n",
            "        641,  429,  157,  162,  799, 1370,   22,  215, 1017,  298,  126,\n",
            "          8,  555,  270,  339,  342, 1434,   30,  397,  620,    6,  209,\n",
            "        419,  283,  188,  267,  245, 1065,  207,  456,  131,   94,  567,\n",
            "        153,   53,  234,  108,  208,  597,  505,  332,  212,  493,  681,\n",
            "        287,  202,   37,   72,  325, 1212,  319,  514,  551,  142,  293,\n",
            "        107,  127, 1816,  200,  418,  387,  156,   47,  265,   31,   28,\n",
            "        369,  854,   46,  266,  321,   99,  430,  264,  118,  343,    5,\n",
            "        722,  748,  523,  421,   15,  502,  193,  347,  468,  388, 1735,\n",
            "        172,  117,  587,  501,  282,  110,  104,  378, 1407,  738,   70,\n",
            "        904,  336,  238,  585,   68, 1713,  218,  661,  566,  136,  160,\n",
            "         44,  792,   73,   90,  346,  192,  682,  651,  405,  350,   36,\n",
            "        389, 3025,  219,  427,  533,   19,  819,  278,  617,   34,  668,\n",
            "         75,  146,  356,  251,  352,  184,  568,  260,  447,  426,  174,\n",
            "        284,  428,  237, 1031,  700,  590,   43,   27, 1181,  122,  307,\n",
            "        770,  767,  232,  986,   66,  158,  306,  559,  183,  631, 1282,\n",
            "       1199,  244,   55,  290,  385,  133,   91,   25,  275,  632,  100,\n",
            "         41,  446,  304,  335,  276,   42,  614,  557, 1663,  510, 1259,\n",
            "        225,  404, 1015,  761,  464,  206,  667,  143,  717,   38,  254,\n",
            "        882,  957,  299,  167,  500,  177,  457,  460, 1028,  315,  381,\n",
            "        643,  508,  128,  492,  257,  241,  536,  601, 1168,  277,  364,\n",
            "        229,  402,  175,  255,  820,  116,  463,  603,  191, 2087,  754,\n",
            "        303,  288,  891,  558,  228,  353,  296,  432, 1130,  305,  274,\n",
            "        860,  420,  756,  968,  408,   13,  763,  316,   50,    4,   78,\n",
            "        286,  766,  648,  688,   21,  593,  407,  563,   52,  803,  396,\n",
            "        637,  945, 1178,  506,  409,  327,  618,  936,  329,  179,  731,\n",
            "        670,  318,  415,  137,  349,  263,  671,  452,  163,  586,  650,\n",
            "        610,  747,  252,  883,  684,  686, 1060,  724,  424,  712,  753,\n",
            "       1081,  376,  433,  411, 1083,  757,  524,  653,   93,  503,  217,\n",
            "        475,  340,  242,  530,   23,  935,  773,  423,  626,  578,  248,\n",
            "        528,  785,  952, 1174,  915,  937,  129, 1063,  758,  574,  847,\n",
            "       1558,  789, 1441,  322, 1504,  537,  611,   26,   12,  235,  796,\n",
            "       1126,  697,  931, 1034,  362,  410,  570,  633,  659,  302,  727,\n",
            "        214,  173,  635,  540, 1210,  486,  646,  326,  414,  716,  449,\n",
            "        580,  399, 1029,  755,  619,  606,  971,  348,  594, 1275,  379,\n",
            "       1032,  393,  808,  923,  413,  541,  602,  762,  360,  310,  311,\n",
            "        638,  355,  300,  417,  308,  657,  434,  488, 1309, 1056,  908,\n",
            "        401,  827,  735,  691,  461,  669, 1473, 1386,  294,  910,  550,\n",
            "       1366, 1532,  955,  513, 1236,  809,  482, 1164,  674,  709,  436,\n",
            "        374,  309,  363,  422,  358,  640,  439,  476,  480,  517,  993,\n",
            "         33,  730,  636,  750,  334,  868,  351, 1689,  607,  485, 1021,\n",
            "        732,  577,  733,  788,  863, 1073,  525,  696,  535,  370,  465,\n",
            "        338,  956,  546,  470,  836,  544,  443, 1149,  707, 1451, 1143,\n",
            "        477,  450,  467,  292,  806,  560,  759, 1183,  598,  466,  431,\n",
            "        269,  542,  562,  515, 1165,  547,  780,  916,  474,  509,  679,\n",
            "       1472,  965, 1139,  504,  672,  749,  454,  531,  479,  384,  973,\n",
            "        728,  656,  998,  320,  615,  612,  664,  394,  877, 1971, 1258,\n",
            "        599,  655, 1994,  743,  924,  929,  491,  719,  565, 1529,  390,\n",
            "       1467, 1007,  665,  990,  582,  458,  775,  497,  698,  702,  520,\n",
            "       1156,  884, 1521,  359,  527,  994, 1579,  437, 1225,  865,  569,\n",
            "       1011,  814,  984,  392,  595, 1448,  529, 1006,  622,  494, 1022,\n",
            "       1044,  781, 1124,  400,  516, 1516,  978,  720,  495,  798,  876,\n",
            "        875,  481,  793, 1117, 1223, 1101,  744, 2769,  561,  715,  639,\n",
            "        538, 1721, 1608,  725,  519,  490,  907,  680,  977,  959,  693,\n",
            "       2029, 1009,  718,  805,  623,  976,  600,  469, 1010,  634, 1531,\n",
            "        764,  532,  825,  539,  816,  821, 1231,  742, 2456,  721,  777,\n",
            "        548,  830,  645,  723,  746,  869, 1173,  624,  518,  815,  857,\n",
            "        921,  627,  800,  366, 1088,  812,  866, 1151,  873,  592,  663,\n",
            "        576, 1476,  951, 1234, 1263,  660]), 'campaign': array([ 1,  4,  2,  5,  3,  6, 18, 10,  9,  7, 12, 14, 13, 24, 11,  8, 29,\n",
            "       32, 16, 22, 15, 30, 25, 21, 17, 19, 23, 20, 50, 28, 31, 44]), 'pdays': array([ -1, 339, 330, 176, 147, 241, 152, 105, 342, 101,   5,  92,  56,\n",
            "       170, 182, 297, 196, 460, 137, 367, 145, 169, 207, 266, 288, 168,\n",
            "       345, 436,  90, 183, 146, 335, 347, 119,   7, 271, 181,  88, 141,\n",
            "       126,  61, 373, 351, 242,  62,  91, 308, 250, 172, 265,  78,  28,\n",
            "        79,   1, 188, 167,  89, 164, 462, 209, 321, 254,  94, 364,  96,\n",
            "       356, 149, 363, 275, 325, 341, 260, 358,  87, 303,  98, 327, 337,\n",
            "       322, 102,  99, 370,  84, 212,  63,  81, 191, 360, 332,  80,  85,\n",
            "       247, 150, 175, 382, 261, 336,  58, 206, 112, 199, 133, 208, 253,\n",
            "       135, 278, 140, 298, 273, 124, 281, 162, 323, 349, 117,   2, 256,\n",
            "       333, 116, 268, 136, 198, 357, 259, 353, 174, 371, 205, 246,  69,\n",
            "       315, 110, 461, 184, 270, 127, 187,  64, 130, 346, 100, 352, 808,\n",
            "       113, 378, 292, 287, 107, 293, 139, 138, 193, 274,  97, 103, 359,\n",
            "       185, 674, 211, 300, 334, 280, 479,  95, 262, 362, 225,   3, 366,\n",
            "        60, 190, 368, 122, 343, 131, 365, 299, 115, 316, 180, 154, 313,\n",
            "       264, 350,  73, 232, 204, 143, 375, 186, 344, 210, 248, 177, 221,\n",
            "       189, 104, 258, 305, 171, 120, 317, 178, 386, 118, 404, 374, 282,\n",
            "       179, 284, 227, 291, 173, 871, 238, 294, 222, 435, 340, 426, 239,\n",
            "        83, 111, 415, 255, 235, 244,  38, 683, 329,  59, 151, 192, 158,\n",
            "       338, 388, 165, 348, 197, 295, 109, 484, 326, 369, 397, 414, 319,\n",
            "       474,  93, 249, 272, 355, 195,  82, 541, 231, 153, 201, 761, 114,\n",
            "       385, 267, 161, 467,  75, 106, 223, 312, 148, 309, 283,  86, 166,\n",
            "       160, 450, 500, 311, 123, 159, 687, 224, 361,  74,  76, 286,  77,\n",
            "        57, 219, 331, 804, 144, 234]), 'previous': array([ 0,  4,  1,  3,  2,  5, 20,  7,  6, 10,  9,  8, 18, 19, 12, 13, 11,\n",
            "       14, 15, 24, 17, 22, 23, 25]), 'poutcome': array(['unknown', 'failure', 'other', 'success'], dtype=object)}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pbP4-Ud7z_Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "8dc55f4a-3284-43cc-8410-5aa493761592"
      },
      "source": [
        "# convert df to data examples\n",
        "array = df.head(4000).values\n",
        "set1 = []\n",
        "set2 = []\n",
        "set3 = []\n",
        "set4 = []\n",
        "possible_split_features = title[:-1]\n",
        "count = 0\n",
        "for i in range(len(array)):\n",
        "    count += 1\n",
        "    if (count <= 1000):\n",
        "        set1.append(array[i])\n",
        "    elif (count > 1000 and count <= 2000):\n",
        "        set2.append(array[i])\n",
        "    elif (count > 2000 and count <= 3000):\n",
        "        set3.append(array[i])    \n",
        "    else:\n",
        "        set4.append(array[i])\n",
        "# to simulate continous training, modify the tree for each training set\n",
        "examples = [set1, set2, set3, set4]\n",
        "\n",
        "print(set1[:5])"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[array([30, 'unemployed', 'married', 'primary', 'no', 1787, 'no', 'no',\n",
            "       'cellular', 19, 10, 79, 1, -1, 0, 'unknown', 'no'], dtype=object), array([33, 'services', 'married', 'secondary', 'no', 4789, 'yes', 'yes',\n",
            "       'cellular', 11, 5, 220, 1, 339, 4, 'failure', 'no'], dtype=object), array([35, 'management', 'single', 'tertiary', 'no', 1350, 'yes', 'no',\n",
            "       'cellular', 16, 4, 185, 1, 330, 1, 'failure', 'no'], dtype=object), array([30, 'management', 'married', 'tertiary', 'no', 1476, 'yes', 'yes',\n",
            "       'unknown', 3, 6, 199, 4, -1, 0, 'unknown', 'no'], dtype=object), array([59, 'blue-collar', 'married', 'secondary', 'no', 0, 'yes', 'no',\n",
            "       'unknown', 5, 5, 226, 1, -1, 0, 'unknown', 'no'], dtype=object)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCLfMVs-8Rk6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test set is different from training set\n",
        "n_test = 500\n",
        "test_set = df.tail(n_test).values\n",
        "test = []\n",
        "for i in range(len(test_set)):\n",
        "    test.append(test_set[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rc6Tbv-x5KBO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Codes are copied but changed some part of codes to fit my bank Dataset \n",
        "#Source and references:\n",
        "#https://homes.cs.washington.edu/~pedrod/papers/kdd00.pdf\n",
        "#http://huawei-noah.github.io/streamDM/docs/HDT.html\n",
        "#https://github.com/doubleplusplus/incremental_decision_tree-CART-Random_Forest_python/blob/master/vfdt.py\n",
        "\n",
        "# VFDT node class\n",
        "class vfdt_node:\n",
        "    \n",
        "    def __init__(self, possible_split_features):\n",
        "        self.parent = None\n",
        "        self.left_child = None\n",
        "        self.right_child = None\n",
        "        self.split_feature = None\n",
        "        self.split_value = None\n",
        "        self.new_examples_seen = 0\n",
        "        self.total_examples_seen = 0\n",
        "        self.class_frequency = {}\n",
        "        self.nijk = {i:{} for i in possible_split_features}\n",
        "        self.possible_split_features = possible_split_features\n",
        "\n",
        "    def add_children(self, split_feature, left, right):\n",
        "        self.split_feature = split_feature\n",
        "        self.left_child = left\n",
        "        self.right_child = right\n",
        "        left.parent = self\n",
        "        right.parent = self\n",
        "        self.nijk.clear()  # reset stats\n",
        "\n",
        "    # recursively trace down the tree to distribute data examples to corresponding leaves\n",
        "    def sort_example(self, example):\n",
        "        if (not self.is_leaf()):\n",
        "            index = self.possible_split_features.index(self.split_feature)\n",
        "            value = example[:-1][index]\n",
        "\n",
        "            try:  # continous value\n",
        "                if value <= self.split_value:\n",
        "                    return self.left_child.sort_example(example)\n",
        "                else:\n",
        "                    return self.right_child.sort_example(example)\n",
        "            except TypeError:  # discrete value\n",
        "                if value in self.split_value[0]:\n",
        "                    return self.left_child.sort_example(example)\n",
        "                else:\n",
        "                    return self.right_child.sort_example(example)\n",
        "        else:\n",
        "            return(self)\n",
        "\n",
        "    def is_leaf(self):\n",
        "        return(self.left_child == None and self.right_child == None)\n",
        "\n",
        "    # the most frequent classification\n",
        "    def most_frequent(self):\n",
        "        if (self.class_frequency):\n",
        "            prediction = max(self.class_frequency, key=self.class_frequency.get)\n",
        "        else:\n",
        "            # if self.class_frequency dict is empty, go back to parent\n",
        "            class_frequency = self.parent.class_frequency\n",
        "            prediction = max(class_frequency, key=class_frequency.get)\n",
        "        return(prediction)\n",
        "\n",
        "    # upadate leaf stats in order to calculate infomation gain\n",
        "    def update_stats(self, example):\n",
        "        label = example[-1]\n",
        "        feats = self.possible_split_features\n",
        "        for i in feats:\n",
        "            if (i != None):\n",
        "                value = example[:-1][feats.index(i)]\n",
        "                if (value not in self.nijk[i]):\n",
        "                    d = {label : 1}\n",
        "                    self.nijk[i][value] = d\n",
        "                else:\n",
        "                    if (label not in self.nijk[i][value]):\n",
        "                        self.nijk[i][value][label] = 1\n",
        "                    else:\n",
        "                        self.nijk[i][value][label] += 1\n",
        "        self.total_examples_seen += 1\n",
        "        self.new_examples_seen += 1\n",
        "        if (label not in self.class_frequency):\n",
        "            self.class_frequency[label] = 1\n",
        "        else:\n",
        "            self.class_frequency[label] += 1\n",
        "\n",
        "    def check_not_splitting(self):\n",
        "        # compute Gini index for not splitting\n",
        "        X0 = 1\n",
        "        class_frequency = self.class_frequency\n",
        "        n = sum(class_frequency.values())\n",
        "        for j, k in class_frequency.items():\n",
        "            X0 -= (k/n)**2\n",
        "        return X0\n",
        "\n",
        "    # use hoeffding tree model to test node split, return the split feature\n",
        "    def splittable(self, delta, nmin, tau):\n",
        "        if(self.new_examples_seen < nmin):\n",
        "            return(None)\n",
        "        else:\n",
        "            self.new_examples_seen = 0  # reset\n",
        "        nijk = self.nijk\n",
        "        min = 1\n",
        "        second_min = 1\n",
        "        Xa = ''\n",
        "        split_value = None\n",
        "        for feature in self.possible_split_features:\n",
        "            if (len(nijk[feature]) != 1):\n",
        "                gini, value = self.Gini(feature)\n",
        "                if (gini < min):\n",
        "                    min = gini\n",
        "                    Xa = feature\n",
        "                    split_value = value\n",
        "                elif (min < gini < second_min):\n",
        "                    second_min = gini\n",
        "            else:\n",
        "                return None\n",
        "\n",
        "        sigma = self.hoeffding_bound(delta)\n",
        "        X0 = self.check_not_splitting()\n",
        "        if min < X0:\n",
        "            if (second_min - min > sigma):\n",
        "                return [Xa, split_value]\n",
        "            elif (sigma < tau and second_min - min < tau):\n",
        "                return [Xa, split_value]\n",
        "            else:\n",
        "                return None\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "    def hoeffding_bound(self, delta):\n",
        "        n = self.total_examples_seen\n",
        "        R = np.log(len(self.class_frequency))\n",
        "        return (R * R * np.log(1/delta) / (2 * n))**0.5\n",
        "\n",
        "    def Gini(self, feature):\n",
        "        '''\n",
        "        Gini(D) = 1 - Sum(pi^2)\n",
        "        Gini(D, F=f) = |D1|/|D|*Gini(D1) + |D2|/|D|*Gini(D2)\n",
        "        '''\n",
        "        njk = self.nijk[feature]\n",
        "        D = self.total_examples_seen\n",
        "        class_frequency = self.class_frequency\n",
        "\n",
        "        m1 = 1  # minimum gini\n",
        "        m2 = 1  # second minimum gini\n",
        "        Xa_value = None\n",
        "        test = next(iter(njk))  # test j value\n",
        "        # if not isinstance(test, np.object):\n",
        "        try:  # continous feature values\n",
        "            test += 0\n",
        "            sort = sorted([j for j in njk.keys()])\n",
        "            split = []\n",
        "            for i in range(1, len(sort)):\n",
        "                temp = (sort[i-1] + sort[i])/2\n",
        "                split.append(temp)\n",
        "\n",
        "            D1 = 0\n",
        "            D1_class_frequency = {j:0 for j in class_frequency.keys()}\n",
        "            for index in range(len(split)):\n",
        "                nk = njk[sort[index]]\n",
        "\n",
        "                for j in nk:\n",
        "                    D1_class_frequency[j] += nk[j]\n",
        "                D1 += sum(nk.values())\n",
        "                D2 = D - D1\n",
        "                g_d1 = 1\n",
        "                g_d2 = 1\n",
        "\n",
        "                D2_class_frequency = {}\n",
        "                for key, value in class_frequency.items():\n",
        "                    if key in D1_class_frequency:\n",
        "                        D2_class_frequency[key] = value - D1_class_frequency[key]\n",
        "                    else:\n",
        "                        D2_class_frequency[key] = value\n",
        "\n",
        "                for key, v in D1_class_frequency.items():\n",
        "                    g_d1 -= (v/float(D1))**2\n",
        "                for key, v in D2_class_frequency.items():\n",
        "                    g_d2 -= (v/float(D2))**2\n",
        "                g = g_d1*D1/D + g_d2*D2/D\n",
        "                if g < m1:\n",
        "                    m1 = g\n",
        "                    Xa_value = split[index]\n",
        "                elif m1 < g < m2:\n",
        "                    m2 = g\n",
        "            return [m1, Xa_value]\n",
        "\n",
        "        # discrete feature_values\n",
        "        except TypeError:\n",
        "            length = len(njk)\n",
        "            feature_values = list(njk.keys())\n",
        "            right = None\n",
        "            if length > 10:  # too many discrete feature values\n",
        "                for j, k in njk.items():\n",
        "                    D1 = sum(k.values())\n",
        "                    D2 = D - D1\n",
        "                    g_d1 = 1\n",
        "                    g_d2 = 1\n",
        "\n",
        "                    D2_class_frequency = {}\n",
        "                    for key, value in class_frequency.items():\n",
        "                        if key in k:\n",
        "                            D2_class_frequency[key] = value - k[key]\n",
        "                        else:\n",
        "                            D2_class_frequency[key] = value\n",
        "\n",
        "                    for key, v in k.items():\n",
        "                        g_d1 -= (v/D1)**2\n",
        "\n",
        "                    if D2 != 0:\n",
        "                        for key, v in D2_class_frequency.items():\n",
        "                            g_d2 -= (v/D2)**2\n",
        "                    g = g_d1*D1/D + g_d2*D2/D\n",
        "                    if g < m1:\n",
        "                        m1 = g\n",
        "                        Xa_value = j\n",
        "                    elif m1 < g < m2:\n",
        "                        m2 = g\n",
        "                right = list(np.setdiff1d(feature_values, Xa_value))\n",
        "\n",
        "            else:  # fewer discrete feature values\n",
        "                comb = self.select_combinations(feature_values)\n",
        "                for i in comb:\n",
        "                    left = list(i)\n",
        "                    D1 = 0\n",
        "                    D2 = 0\n",
        "                    D1_class_frequency = {key:0 for key in class_frequency.keys()}\n",
        "                    D2_class_frequency = {key:0 for key in class_frequency.keys()}\n",
        "                    for j,k in njk.items():\n",
        "                        for key, value in class_frequency.items():\n",
        "                            if j in left:\n",
        "                                if key in k:\n",
        "                                    D1 += sum(k.values())\n",
        "                                    D1_class_frequency[key] += k[key]\n",
        "                            else:\n",
        "                                if key in k:\n",
        "                                    D2 += sum(k.values())\n",
        "                                    D2_class_frequency[key] += k[key]\n",
        "                    g_d1 = 1\n",
        "                    g_d2 = 1\n",
        "                    for key, v in D1_class_frequency.items():\n",
        "                        g_d1 -= (v/D1)**2\n",
        "                    for key, v in D2_class_frequency.items():\n",
        "                        g_d2 -= (v/D1)**2\n",
        "                    g = g_d1*D1/D + g_d2*D2/D\n",
        "                    if g < m1:\n",
        "                        m1 = g\n",
        "                        Xa_value = left\n",
        "                    elif m1 < g < m2:\n",
        "                        m2 = g\n",
        "                right = list(np.setdiff1d(feature_values, Xa_value))\n",
        "            return [m1, [Xa_value, right]]\n",
        "\n",
        "    def select_combinations(self, feature_values):\n",
        "        combination = []\n",
        "        e = len(feature_values)\n",
        "        if e % 2 == 0:\n",
        "            end = int(e/2)\n",
        "            for i in range(1, end+1):\n",
        "                if i == end:\n",
        "                    cmb = list(combinations(feature_values, i))\n",
        "                    enough = int(len(cmb)/2)\n",
        "                    combination.extend(cmb[:enough])\n",
        "                else:\n",
        "                    combination.extend(combinations(feature_values, i))\n",
        "        else:\n",
        "            end = int((e-1)/2)\n",
        "            for i in range(1, end+1):\n",
        "                combination.extend(combinations(feature_values, i))\n",
        "\n",
        "        return combination"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8xIYngZ5PjO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# very fast decision tree class, i.e. hoeffding tree\n",
        "class vfdt:\n",
        "    # parameters\n",
        "    # feature_values  # number of values of each feature # dict\n",
        "    # feature_values = {feature:[unique values list]}\n",
        "    # delta   # used for hoeffding bound\n",
        "    # tau  # used to deal with ties\n",
        "    # nmin  # used to limit the G computations\n",
        "\n",
        "    def __init__(self, feature_values, delta=0.05, nmin=50, tau=0.1):\n",
        "        self.feature_values = feature_values\n",
        "        self.delta = delta\n",
        "        self.nmin = nmin\n",
        "        self.tau = tau\n",
        "        features = list(feature_values.keys())\n",
        "        self.root = vfdt_node(features)\n",
        "        self.n_examples_processed = 0\n",
        "\n",
        "    # update the tree by adding training example\n",
        "    def update(self, example):\n",
        "        self.n_examples_processed += 1\n",
        "        node = self.root.sort_example(example)\n",
        "        node.update_stats(example)\n",
        "\n",
        "        result = node.splittable(self.delta, self.nmin, self.tau)\n",
        "        if result != None:\n",
        "            feature = result[0]\n",
        "            value = result[1]\n",
        "            self.node_split(node, feature)\n",
        "            node.split_value = value\n",
        "\n",
        "    # split node, produce children\n",
        "    def node_split(self, node, split_feature):\n",
        "        features = node.possible_split_features\n",
        "        # replace deleted split feature with None\n",
        "        # new_features = [None if f == split_feature else f for f in features]\n",
        "        left = vfdt_node(features)\n",
        "        right = vfdt_node(features)\n",
        "        node.add_children(split_feature, left, right)\n",
        "\n",
        "    # predict test example's classification\n",
        "    def predict(self, example):\n",
        "        leaf = self.root.sort_example(example)\n",
        "        prediction = leaf.most_frequent()\n",
        "        return(prediction)\n",
        "\n",
        "    # accuracy of a test set\n",
        "    def accuracy(self, examples):\n",
        "        correct = 0\n",
        "        for ex in examples:\n",
        "            if (self.predict(ex) == ex[-1]):\n",
        "                correct +=1\n",
        "        return(float(correct) / len(examples))\n",
        "\n",
        "    def print_tree(self, node):\n",
        "        if node.is_leaf():\n",
        "            print('Leaf')\n",
        "        else:\n",
        "            print(node.split_feature)\n",
        "            self.print_tree(node.left_child)\n",
        "            self.print_tree(node.right_child)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7pDhHBw8cYN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "0dc34747-f17f-4261-8d16-0bab9e8bc053"
      },
      "source": [
        "# heoffding bound parameter delta: with 1 - delta probability\n",
        "# the true mean is at least r - gamma\n",
        "# vfdt parameter nmin: test split if new sample size > nmin\n",
        "start_time = time.time()\n",
        "tree = vfdt(feature_values, delta=0.05, nmin=100, tau=0.05)\n",
        "print('Total data size: ', rows,'\\n')\n",
        "print('Test set (tail): ', len(test_set),'\\n')\n",
        "n = 0\n",
        "for training_set in examples:\n",
        "    n += len(training_set)\n",
        "    for ex in training_set:\n",
        "        tree.update(ex)\n",
        "    print('Training set:', n, end=', ')\n",
        "    print('ACCURACY: %.4f \\n' % tree.accuracy(test))\n",
        "\n",
        "#tree.print_tree(tree.root)\n",
        "print(\"--- Running time: %.6f seconds ---\" % (time.time() - start_time))\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total data size:  4521 \n",
            "\n",
            "Test set (tail):  500 \n",
            "\n",
            "Training set: 1000, ACCURACY: 0.8840 \n",
            "\n",
            "Training set: 2000, ACCURACY: 0.8840 \n",
            "\n",
            "Training set: 3000, ACCURACY: 0.8840 \n",
            "\n",
            "Training set: 4000, ACCURACY: 0.8860 \n",
            "\n",
            "--- Running time: 0.287230 seconds ---\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}